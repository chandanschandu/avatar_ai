<!DOCTYPE html>
<html lang="en">
<head>
  <title>Chandan S - AI Portfolio</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body, html { width:100%; height:100%; margin:0; padding:0; background:#121212; color:#E0E0E0; font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; overflow:hidden; display:flex; flex-direction:column; }
    #header { background:#1E1E1E; padding:15px 30px; border-bottom:1px solid #333; text-align:center; }
    #header h1 { margin:0; font-size:2em; color:#fff; }
    #main-container { display:flex; flex:1; overflow:hidden; }
    #avatar-container { flex:1; display:flex; justify-content:center; align-items:center; min-width:50%; pointer-events:none; background-image:url('images/bg.jpg'); background-size:cover; background-position:center; }
    #avatar { width:100%; height:100%; max-width:900px; max-height:900px; }
    #chat-container { flex:1; background:#1E1E1E; border-left:1px solid #333; display:flex; flex-direction:column; padding:20px; box-sizing:border-box; max-width:500px; }
    #chat-messages { flex:1; overflow-y:auto; padding-right:10px; margin-bottom:15px; min-height:0; }
    .message { margin-bottom:15px; padding:10px 15px; border-radius:18px; max-width:85%; line-height:1.4; }
    .message.user { background:#373737; color:#E0E0E0; align-self:flex-end; border-bottom-right-radius:4px; margin-left:auto; }
    .message.bot { background:#BB86FC; color:#121212; align-self:flex-start; border-bottom-left-radius:4px; }
    #chat-input-container { display:flex; border-top:1px solid #333; padding-top:15px; }
    #chat-input { flex:1; background:#373737; color:#E0E0E0; border:1px solid #555; border-radius:20px; padding:10px 15px; font-size:1em; outline:none; }
    #send-button, #stop-button, #mic-button { border:none; border-radius:50%; width:40px; height:40px; cursor:pointer; font-size:1.2em; display:flex; justify-content:center; align-items:center; margin-left:10px; }
    #send-button { background:#BB86FC; color:#121212; } #send-button:hover { background:#a06cd5; }
    #stop-button { background:#ff6b6b; color:#121212; display:none; } #stop-button:hover { background:#e05252; }
    #mic-button { background:#6c757d; color:#fff; } #mic-button.listening { background:#dc3545; }
    #loading { position:absolute; bottom:10px; left:10px; font-size:16px; background:rgba(0,0,0,0.5); padding:5px; border-radius:3px; }
  </style>

  <script type="importmap">
    {
      "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.180.0/build/three.module.js/+esm",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.180.0/examples/jsm/",
        "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.5/modules/talkinghead.mjs"
      }
    }
  </script>

  <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>

  <script type="module">
    import { TalkingHead } from "talkinghead";

    const visemeMap = ["sil","aa","aa","O","E","RR","I","U","O","O","O","I","kk","RR","nn","SS","CH","TH","FF","DD","kk","PP"];
    let head, microsoftSynthesizer = null;
    let visemesbuffer = { visemes:[], vtimes:[], vdurations:[] };
    let prevViseme = null;
    let currentBotMessageElem = null;
    let speechStartTime = 0;
    let synthesisInProgress = false;
    let wordSchedule = [], scheduledTimers = [];
    const playbackLatencyMs = 2000;

    function resetLipsyncBuffers(){ visemesbuffer={visemes:[],vtimes:[],vdurations:[]}; prevViseme=null; }
    function clearScheduledTimers(){ for(const t of scheduledTimers) clearTimeout(t); scheduledTimers=[]; }
    function scheduleWord(idx, chatMessages){ const w=wordSchedule[idx]; if(!w||w.scheduled) return; w.scheduled=true; const displayAt=speechStartTime+w.time+playbackLatencyMs; const delay=Math.max(0,displayAt-performance.now()); const tid=setTimeout(()=>{ if(!synthesisInProgress||!currentBotMessageElem) return; currentBotMessageElem.textContent+=(currentBotMessageElem.textContent?" ":"")+w.text; if(chatMessages) chatMessages.scrollTop=chatMessages.scrollHeight; },delay); scheduledTimers.push(tid); }
    function schedulePendingWords(chatMessages){ for(let i=0;i<wordSchedule.length;i++){ if(!wordSchedule[i].scheduled) scheduleWord(i,chatMessages); } }

    document.addEventListener('DOMContentLoaded', async () => {
      const nodeAvatar=document.getElementById('avatar');
      const nodeLoading=document.getElementById('loading');
      const chatMessages=document.getElementById('chat-messages');
      const chatInput=document.getElementById('chat-input');
      const sendButton=document.getElementById('send-button');
      const stopButton=document.getElementById('stop-button');
      const micButton=document.getElementById('mic-button');

      nodeLoading.textContent="Loading Avatar...";
      head=new TalkingHead(nodeAvatar,{ttsEndpoint:"/api/gtts/", cameraView:"upper", lipsyncLang:"en"});

      try {
        await head.showAvatar({
          url:"https://models.readyplayer.me/68c22c1a8ac0d37a66b6df1c.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png",
          body:"F"
        }, ev => { if(ev.lengthComputable) nodeLoading.textContent=`Loading ${Math.round((ev.loaded/ev.total)*100)}%`; });
        nodeLoading.style.display="none";
        await initializeAzureTTS();
        startConversation();
      } catch(err) {
        console.error("Error loading avatar:",err);
        nodeLoading.textContent="Failed to load avatar.";
      }

      // --- Azure TTS setup ---
      async function initializeAzureTTS() {
        if (microsoftSynthesizer) return;
        try {
          const response = await fetch('/api/tts-token');
          const token = await response.json();
          const config = window.SpeechSDK.SpeechConfig.fromSubscription(token.key, token.region);
          config.speechSynthesisOutputFormat = window.SpeechSDK.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3;
          const audioConfig = window.SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
          microsoftSynthesizer = new window.SpeechSDK.SpeechSynthesizer(config, audioConfig);

          microsoftSynthesizer.synthesizing = (s,e)=>{ if(speechStartTime===0)speechStartTime=performance.now(); if(!head.isStreaming){ head.streamStart({sampleRate:48000,lipsyncType:'visemes',lipsyncLang:'en',waitForAudioChunks:true,mood:'happy',gain:0.5}); } head.streamAudio({audio:e.result.audioData, visemes:visemesbuffer.visemes.splice(0), vtimes:visemesbuffer.vtimes.splice(0), vdurations:visemesbuffer.vdurations.splice(0)}); schedulePendingWords(chatMessages); };
          microsoftSynthesizer.visemeReceived=(s,e)=>{ const vtime=e.audioOffset/10000; const viseme=visemeMap[e.visemeId]; if(!head.isStreaming) return; if(prevViseme){ let vduration=vtime-prevViseme.vtime; if(vduration<40) vduration=40; visemesbuffer.visemes.push(prevViseme.viseme); visemesbuffer.vtimes.push(prevViseme.vtime); visemesbuffer.vdurations.push(vduration); } prevViseme={viseme,vtime}; };
          microsoftSynthesizer.wordBoundary=(s,e)=>{ if(!synthesisInProgress) return; const timeMs=e.audioOffset/10000; const idx=wordSchedule.length; wordSchedule.push({text:e.text,time:timeMs,scheduled:false}); if(speechStartTime!==0) scheduleWord(idx,chatMessages); };
        } catch(err){ console.error("initializeAzureTTS error:",err); }
      }

      function azureSpeak(ssml,botMessageElem){
        clearScheduledTimers(); wordSchedule=[]; speechStartTime=0; currentBotMessageElem=botMessageElem; synthesisInProgress=true;
        if(!microsoftSynthesizer){ initializeAzureTTS().catch(console.error); return; }
        try{
          microsoftSynthesizer.speakSsmlAsync(ssml,()=>{ if(prevViseme){ visemesbuffer.visemes.push(prevViseme.viseme); visemesbuffer.vtimes.push(prevViseme.vtime); visemesbuffer.vdurations.push(200); prevViseme=null; head.streamAudio({audio:new Uint8Array(0), visemes:visemesbuffer.visemes.splice(0), vtimes:visemesbuffer.vtimes.splice(0), vdurations:visemesbuffer.vdurations.splice(0)}); } if(currentBotMessageElem){ currentBotMessageElem.textContent=wordSchedule.map(w=>w.text).join(' ')||currentBotMessageElem.textContent; } clearScheduledTimers(); wordSchedule=[]; currentBotMessageElem=null; synthesisInProgress=false; stopButton.style.display="none"; },err=>{ console.error("Azure TTS error:",err); resetAllState(); });
        } catch(err){ console.error("speakSsmlAsync exception:",err); resetAllState(); }
      }

      function addMessage(text,sender){ const el=document.createElement('div'); el.classList.add('message',sender); el.textContent=text; chatMessages.appendChild(el); chatMessages.scrollTop=chatMessages.scrollHeight; return el; }
      function startConversation(){ addMessage("Hello! I'm an AI avatar representing Chandan S. You can ask me about his skills, experience, projects, or anything else you'd like to know.",'bot'); }
      function resetAllState(){ synthesisInProgress=false; currentBotMessageElem=null; speechStartTime=0; clearScheduledTimers(); wordSchedule=[]; stopButton.style.display="none"; }

      // --- UI hooks ---
      sendButton.addEventListener("click",()=>{ handleUserMessage(chatInput.value.trim()); });
      chatInput.addEventListener("keydown",e=>{ if(e.key==="Enter") handleUserMessage(chatInput.value.trim()); });
      stopButton.addEventListener("click",()=>{ resetAllState(); if(microsoftSynthesizer){ microsoftSynthesizer.close(); microsoftSynthesizer=null; } });
      micButton.addEventListener("click",async()=>{ if(head?.audioContext?.state==="suspended"){ await head.audioContext.resume(); console.log("Audio context resumed."); } addMessage("ðŸŽ¤ Voice input not wired yet.","bot"); });

      async function handleUserMessage(text){
        if(!text) return;
        chatInput.value=""; addMessage(text,"user");
        stopButton.style.display="flex";
        const botEl=addMessage("...",'bot');
        const fakeSSML=`<speak version="1.0" xml:lang="en-US"><voice name="en-US-JennyNeural">${text} back to you!</voice></speak>`;
        botEl.textContent=""; azureSpeak(fakeSSML,botEl);
      }

      // ðŸ”Š resume audio context on first click anywhere
      document.body.addEventListener("click",async()=>{ if(head?.audioContext?.state==="suspended"){ await head.audioContext.resume(); console.log("Audio context resumed on body click."); } },{once:true});
    });
  </script>
</head>
<body>
  <div id="header"><h1>Chandan S - AI Portfolio</h1></div>
  <div id="main-container">
    <div id="avatar-container"><div id="avatar"></div><div id="loading"></div></div>
    <div id="chat-container">
      <div id="chat-messages"></div>
      <div id="chat-input-container">
        <input type="text" id="chat-input" placeholder="Type or press ðŸŽ¤ to talk...">
        <button id="send-button" title="Send">&#9658;</button>
        <button id="mic-button" title="Activate Voice">ðŸŽ¤</button>
        <button id="stop-button" title="Stop Speaking">&#9632;</button>
      </div>
    </div>
  </div>
</body>
</html>
